---
layout: archive
title: "Research"
permalink: /research/
author_profile: true

--- 
Currently, I am working under the guidance of [Professor Christian Wallraven](https://scholar.google.com/citations?hl=tr&user=VJuuzLwAAAAJ&view_op=list_works&sortby=pubdate) in the [Cognitive Systems Lab](https://cogsyslab.notion.site/) at Korea University, where I am investigating the role of internal and external cues in fine-grained ethnicity recognition; whether Koreans can distinguish between [Korean, Chinese, and Japanese faces](https://osf.io/gxky7/). Later, this research led to a follow-up study comparing human and machine learning performance in fine-grained ethnicity recognition. My work aims to deepen our understanding of human perception and its implications for intelligent systems, bridging cognitive science with computational approaches.

My senior bachelor project, "Effects of Perceived Gaze Direction and Face Mask on Emotion Recognition – An Eye-Tracking Study" funded by the Scientific and Technological Research Council of Turkey (TUBITAK), examined how perceived gaze direction and mask usage influence the recognition of emotional facial cues using eye-tracking technology. This study not only aimed to understand how emotion recognition patterns change in mask-wearing environments but also to improve emotion recognition algorithms for masked faces by identifying key facial regions and the role of gaze direction in this process.

Previously, as an undergraduate research assistant under the supervision of [Dr. Funda Yıldırım](https://scholar.google.com/citations?user=mkw1cpwAAAAJ&hl=tr&oi=ao) in the [Computational Neuroscience Visual Perception (CNVP)](https://cnvplab.com/) laboratory at Yeditepe University's Department of Computer Engineering, I worked on the ["Audio-visual Mechanisms of The Uncanny Valley Effect"](https://cnvplab.com/https-cnvplab-com-projects-short-term-plasticity-in-bistable-phonetic-word-processing-visual-crowding-in-holistic-configurations/projects-short-term-plasticity-in-bistable-phonetic-word-processing-186-2/) This project explored how different levels of naturality in visual-auditory stimuli affect human-robot interaction (HRI) and the perception of the Uncanny Valley effect across generations. 


 


