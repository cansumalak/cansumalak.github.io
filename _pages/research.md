---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---

## Overview

Currently, I am working under the guidance of [Professor Christian Wallraven](https://scholar.google.com/citations?hl=tr&user=VJuuzLwAAAAJ&view_op=list_works&sortby=pubdate) in the [Cognitive Systems Lab](https://cogsyslab.notion.site/) at Korea University, where I am investigating [the role of internal and external cues in fine-grained ethnicity recognition; whether Koreans can distinguish between Korean, Chinese, and Japanese faces](https://osf.io/gxky7/). Later, this research led to a follow-up study comparing human and machine learning performance in fine-grained ethnicity recognition. My work aims to deepen our understanding of human perception and its implications for intelligent systems, bridging cognitive science with computational approaches.

---
## Projects (click to expand)

<div class="cm-accordion">

  <details class="cm-item">
    <summary class="cm-header">
      <span>External vs. Internal Facial Features in Fine-Grained Ethnicity Categorization</span>
      <span class="cm-tag">Behavioral · Face perception</span>
    </summary>
    <div class="cm-body">
      <p>
        I examine how Korean observers use <strong>internal features</strong> (e.g., eyes/nose)
        versus <strong>external cues</strong> (e.g., hair/face outline) when categorizing
        Korean, Japanese, and Chinese faces, and how background/context modulates this process.
      </p>
      <p class="cm-meta"><strong>Methods:</strong> 3AFC categorization · feature manipulations · confidence measures</p>
      <p class="cm-links"><a href="https://osf.io/gxky7/" target="_blank" rel="noopener">Preprint / OSF</a></p>
    </div>
  </details>

  <details class="cm-item">
    <summary class="cm-header">
      <span>Humans vs. Machines: Comparing Strategies in Fine-Grained Face Categorization</span>
      <span class="cm-tag">Computational · Human–AI</span>
    </summary>
    <div class="cm-body">
      <p>
        Building on the behavioral findings, I compare human performance with deep learning models
        to understand where humans struggle, where machines excel, and whether they rely on different facial information.
      </p>
      <p class="cm-meta"><strong>Methods:</strong> embeddings/classifiers · cross-validation · error analysis</p>
    </div>
  </details>

  <details class="cm-item">
    <summary class="cm-header">
      <span>Gaze Direction × Face Mask Effects on Emotion Recognition (Eye-Tracking)</span>
      <span class="cm-tag">Eye-tracking · Social vision</span>
    </summary>
    <div class="cm-body">
      <p>
        My senior bachelor project investigated how perceived gaze direction and face masks shape
        emotion recognition, and how attention is allocated to diagnostic facial regions.
      </p>
      <p class="cm-meta"><strong>Funding:</strong> TUBITAK</p>
      <p class="cm-links"><a href="https://osf.io/3fd5h/" target="_blank" rel="noopener">Project / OSF</a></p>
    </div>
  </details>

  <details class="cm-item">
    <summary class="cm-header">
      <span>Audio-visual Mechanisms of the Uncanny Valley Effect (HRI)</span>
      <span class="cm-tag">Multisensory · HRI</span>
    </summary>
    <div class="cm-body">
      <p>
        As an undergraduate research assistant in the
        <a href="https://cnvplab.com/" target="_blank" rel="noopener">CNVP Lab</a>,
        I worked on how levels of naturality in visual–auditory stimuli influence human–robot interaction
        and uncanny valley perception across generations.
      </p>
    </div>
  </details>

</div>
